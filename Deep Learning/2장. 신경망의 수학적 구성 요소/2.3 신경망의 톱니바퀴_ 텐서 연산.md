
output = relu(dot(input, W) + b)

1. 입력 텐서와 텐서 W 사이의 점곱
2. 점곱으로 만들어진 행렬과 벡터 b 사이의 뎃셈(+)
3. relu 연산.relu(x)는 max(x, 0)입니다.

#2.3.1 원소별 연산
relu 함수와 덧셈은 원소별 연산이다.

[원소별 연산]
```
def naive_felu(x):
	assert len(x.shape) == 2    #x는 랭크_2 넘파이 배열이다.
	x = x.copy()                #입력 텐서 자체를 바꾸지 않도록 복사한다.
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i, j] = max(x[i, j], 0)
	return x
```

[덧셈]
```
def naive_add(x, y):
	assert len(x.shape) == 2        #x와 y는 랭크_2 넘파이 배열이다.
	assert x.shape == y.shape
	x = x.copy()                    #입력 텐서 자체를 바꾸지 않도록 복사한다.
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			x[i, j] += y[i, j]
	return x
```

넘파이는 BLAS(Basic Linear Algebra Subprogram) 구현에 복잡한 일들을 위임한다.
BLAS는 고도로 병렬화되고 효율적인 저수준의 텐서 조작 루틴이며, 전형적인 포트란이나 C 언어로 구현되어 있다.

#2.3.2 브로드캐스팅
브로드캐스팅 2단계
1. 큰 텐서의 ndim에 맞도록 작은 텐서에 축이 추가됩니다.
2. 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복됩니다.

-----------------------------------------------
여기부터 이해가 안되서 공부하고 다시 필기할것!!


#2.3.3 텐서 곱셈
텐서 곱셈(tensor product) == 점곱(dot product)
넘파이에서 텐서 곱셈은 np.dot을 사용한다.

```
x = np.random.random((32,))
y = np.random.random((32,))
z = np.dot(x, y)
```

[점곱 연산]
```
def naive_vector_dot(x, y):
	assert len(x.shape) == 1
	assert len(y.shape) == 1
	assert x.shape[0] == y.shape[0]
	z = 0.
	for i in range(x.shape[0]):
		z += x[i] * y[i]
	return z
```

```
def naive_matrix_vector_dot(x, y):
	assert len(x.shape) == 2
	assert len(y.shape) == 1
	assert x.shape[1] == y.shape[0]
	z = np.zeros(x.shape[0])
	for i in range(x.shape[0]):
		for j in range(x.shape[1]):
			z[i] += x[i, j] * y[j]
	return z
```

```
def naive_matrix_vector_dot(x, y):
	z = np.zeros(x.shape[0])
	for i in range(x.shape[0]):
		z[i] = naive_vector_dot(x[i, :], y)
	return z
```


```
def naive_matrix_dot(x, y):
	assert len(x.shape) == 2
	assert len(y.shape) == 2
	assert x.shape[1] == y.shape[0]
	z = np.zeros((x.shape[0], y.shape[1]))
	for i in range(x.shape[0]):
		for j in range(y.shape[1]):
			row_x = x[i, :]
			column_y = y[:, j]
			z[i, j] = naive_vector_dot(row_x, column_y)
	return z
```

![[스크린샷 2025-02-12 오후 12.44.15.png]]
-> 걍 행렬 끼리 곱하는거 계산
![[스크린샷 2025-02-12 오후 12.57.54.png]]

#2.3.4 텐서 크기 변환
텐서 크기 변환 : 특정 크기에 맞게 열과 행을 재배열 한다는 뜻.

```
>>>>train_images = train_images.reshape((60000, 28 * 28))

>>>>x = np.array([[0., 1.],
>>>>[2., 3.],
>>>>[4., 5.]])
>>>>x.shape
(3, 2)

>>>>x = x.reshape((6, 1))
>>>>x
array([[0.],
       [1.],
       [2.],
       [3.],
       [4.],
       [5.]])

>>>>x = x.reshape((2, 3))
>>>>x
array([[0., 1., 2.],
       [3., 4., 5.]])
       
>>>>x = np.zeros((300, 20))
>>>>x = np.transpose(x)
>>>>x.shape
```

#2.3.5 텐서 연산의 기하학적 해석
일반적으로 이동(translation), 회전(rotation), 크기 변경(scaling), 기울이기(skewing)이 가능

1.이동: 한 점에 벡터를 더하면 고정된 방향으로 고정된 양만큼 점을 이동시킨다.
![[스크린샷 2025-02-12 오후 2.13.50.png]]

2.회전: 각도 theta만큼 2D 벡터를 반시계 방향 회전한 결과 2x2 행렬 R=[[cos(theta), -sin(theta)], [sin(theta), cos(theta)] ]와 점곱 하여 계산 가능
![[스크린샷 2025-02-12 오후 2.14.00.png]]

3.크기 변경: 
2x2 행렬 S=[[horizontal_factor, 0], [0, vertical_factor]] 와 점곱하여 수직과 수평방향으로 크기를 변경시킨 이미지이다.
![[스크린샷 2025-02-12 오후 2.17.10.png]]

4.선형 변환(linear transfrom): 임의의 행렬과 점곱하면 선형 변환이 수행된다. 
크기 변경과 회전은 선형 변환에 해당됨

5.어파인(affine transform): 어파인 변환은 선형 변환과 이동의 조합이다.
![[스크린샷 2025-02-12 오후 2.17.16.png]]

relu 활성화 함수를 사용하는 Dense 층: 어파인 변환의 
