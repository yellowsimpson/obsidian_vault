

![[스크린샷 2025-02-10 오후 12.26.56.png]]
[코드 2_1 케라스에서 MNIST 데이터셋 적재하기]
```
#딥러닝에 필요한 데이터 셋을 다운로드 해옴
from tensorflow.keras.datasets import mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

#훈련 데이터셋 
train_images.shape
len(train_labels)
train_labels

#테스트 데이터셋
train_labels
test_images.shape
len(test_labels)
test_labels
```

[코드2-2 신경망 구조]
```
from tensorflow import keras
from tensorflow.keras import layers

model = keras.Sequential([
	layers.Dense(512, activation="relu"),
	layers.Dense(10, activation="softmax")
])
```
신경망의 핵심 구성 요소는 층!! 층(layer) == 데이터를 위한 필터(filter)
어떤 데이터가 들어가면 결과가 출력되는데 

[코드2-3 컴파일 단계]
```
#훈련을 시작하기 전 데이터 모델을 0과 1사이로 크기 조정
model.compile(optimizer = "rmsprop",
			  loss = "sparse_categorical_crossentropy",
			  metrics=["accuracy"]
)
```

용어 정리
1. 옵티마이저(optimizer): 성능 향상시키기 위해 입력된 데이터를 기반으로 모델을 업데이트 하는 메커니즘
2. 손실 함수(loss function): 훈련 데이터에서 모델의 성능을 측정하는 방법으로 모델이 옳은 방향으로 학습 될 수 있도록 도와준다.
3. 훈련과 테스트 과정을 모니터링 할 지표: 정확도를 고려해준다.

[코드2-4 이미지 데이터 준비하기]
```
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255
train_images = train_images.reshape((10000, 28 * 28))
train_images = train_images.astype("float") / 255
```

훈련 시작하기 전에 데이터를 모델에 맞는 크기로 바꾸고 모든 값을 0과 1로 사이로 스케일을 조정

```
>>>>model.fit(train_images, train_labels, epochs=5, batch_size=128)

Epoch 1/5
469/469 ━━━━━━━━━━━━━━━━━━━━ 3s 3ms/step - accuracy: 0.8698 - loss: 0.4524
Epoch 2/5
469/469 ━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step - accuracy: 0.9641 - loss: 0.1218
Epoch 3/5
469/469 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9789 - loss: 0.0732
Epoch 4/5
469/469 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9847 - loss: 0.0497
Epoch 5/5
469/469 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.9887 - loss: 0.0390
```

훈련 결과 epoch(훈련 횟수 5번)을 돌리는 동안 accuracy(정확도): 0.9887 - loss(손실 함수): 0.0390의 결과 값이 나왔다.

[코드2-6 모델을 사용하여 예측 만들기]
```
>>>>test_digits = test_images[0:10]
>>>>predictions = model.predict(test_digits)
>>>>predictions[0]

1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 339ms/step

array([3.5515196e-08, 6.5396177e-10, 6.9852094e-06, 5.4760469e-04,
       2.6456117e-11, 2.1925950e-07, 9.3632339e-13, 9.9944121e-01,
       1.5752508e-07, 3.8599464e-06], dtype=float32)
#왼쪽 부터 0부터 시작해 숫자가 늘어남
#숫자 7이 9.9944121e-01의 확률로 가장 높음
```

출력된 배열의 인덱스 i에 있는 숫자는 숫자 이미지 test_digits[0]이 클래스 i에 속할 확률에 해당한다.

첫번째 테스트 숫자는 인덱스 7에서 가장 높은 확률 값을 얻었다. 
```
>>>> predictions[0].argmax()
7
>>>predictions[0][7]
0.9994412
>>>>test_labels[0]
7
```

[코드2-7 새로운 데이터에서 모델 평가하기]
```
>>>>test_loss, test_acc = model.evaluate(test_images, test_labels)
>>>>print(f"테스트 정확도: {test_acc}")

313/313 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.9763 - loss: 0.0741 테스트 정확도: 0.980400025844574
```

데스트 세트 결과 정확도는 98정도가 나왔다. 
훈련 정확도와 테스트 정확도 사이의 차이는 과대적합 때문이다.
->머신 러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경향을 말한다.

